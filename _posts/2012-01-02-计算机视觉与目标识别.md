---
layout:     post
title:      计算机视觉与目标识别
subtitle:   白贲，无饰
date:       2012-01-02
author:     Rainsblue.chan
header-img: ![3](../../../wallpaper/3.jpg)
catalog:   true
tags:
    - 经验
---

# 计算机视觉与目标识别

## 前言

用于学习计算机视觉与目标识别的笔记，共勉。目录详见右侧。

个人笔记，目的是参加比赛玩以及为毕业设计做准备。

## 第1讲 课程介绍 from 叶梓

### 本章内容

- 计算机视觉概述
- 研究挑战
- 课程简介
- 开源库与应用环境介绍
- 参考书
- 环境搭建

### 计算机视觉概述

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101335108.png" alt="image-20231010133524613" style="zoom: 50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101335333.png" alt="image-20231010133548089" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101337228.png" alt="image-20231010133722991" style="zoom:80%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101338965.png" alt="image-20231010133854666" style="zoom:80%;" />

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101340308.png" alt="image-20231010134013492" style="zoom:80%;" />

比如：医生一直来看片子就会觉得很疲倦，影响效率，可能导致看错，所以计算机视觉可以提供很大的帮助

### 模拟眼睛，大脑

![image-20231010134755298](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101347637.png)

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101348538.png" alt="image-20231010134820045" style="zoom:80%;" />

和很多都有关系

### 2个主要研究维度

- 语义感知（semantic）
- 几何属性（Geometry）

### 语义感知（有很多种类）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101353273.png" alt="image-20231010135334448" style="zoom: 80%;" />

- 分类——物体，属性
- 检测——物体，行人，人脸
- 识别
- 分割
- 检索——以图搜图（类似百度）
- 语言

### 为什么计算机视觉那么难？

![image-20231010135602811](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101356685.png)

### 人工智能目标

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101356181.png" alt="image-20231010135631639" style="zoom:80%;" />

### 研究挑战

- 视角变化

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101405796.png" alt="image-20231010140519236" style="zoom:67%;" />

- 光照变化

![image-20231010140541664](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101405139.png)

- 尺度变化
- 形态变化（小猫小狗缩成一团）

- 背景混淆干扰
- 遮挡

<img src="C:/Users/14682/AppData/Roaming/Typora/typora-user-images/image-20231010140641468.png" alt="image-20231010140641468" style="zoom:50%;" />

- 类内物体的外观差异（都是椅子，但是样式不同，要让计算机理解它是同一类）

### 课程简介

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101407282.png" alt="image-20231010140736879" style="zoom:80%;" />

计算机视觉与目标识别**不仅仅与深度学习有关**，它来源于神经网络以及很多不同种类的东西，不是一个孤立存在的。

深度学习这些网络怎么来的，比如从第二课开始，图像预处理是非常非常重要的，后面哪怕算法再高明，如果对比度调差了，就可能出问题。

所以部分1很重要，深度学习最关键的内容之一就是卷积。如果搞不懂它后面就很难弄。

我们需要了解它的发展。

从第二部分开始才和深度学习有关系。必须要搞清楚**BP神经网络**，这个搞懂才能画瓢，这是最重要，承上启下。

真正的应用部分在第三部分，是深度学习在计算机视觉中的应用。里面还会插入一个，叫图像检索的内容，有一个介绍。

传统的技术也有，新的技术也有。统共十四课。

### 主要研究问题

#### 图像预处理

- 图像显示与存储原理
- 图像增强的目标
- 点运算：基于直方图的对比度增强
- 形态学处理
- 空间域处理：**卷积**
- 卷积的应用（平滑、边缘检测、锐化等）
- 频率域处理：傅里叶变换、小波变换（前者是其基础）

#### 图像特征及描述

<img src="C:/Users/14682/AppData/Roaming/Typora/typora-user-images/image-20231010142400446.png" alt="image-20231010142400446" style="zoom:80%;" />

#### 深度学习之前的方法

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101425386.png" alt="image-20231010142504900" style="zoom:67%;" />

比如抠图，头像分割，还是很有用，不输给深度学习算法，deeplab理论依据

传统人脸检测用haar小波做人脸特征和级联分类器（有点像集成学习，三个臭皮匠，顶个诸葛亮）

HOG是对于每一个块做一个算法，有了这个算法可以把人的模块抠出来

DPM是深度前最牛的

#### 神经网络与深度学习基础

![image-20231010142758856](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101428756.png)

#### 识别->内容是什么？

<img src="C:/Users/14682/AppData/Roaming/Typora/typora-user-images/image-20231010142847699.png" alt="image-20231010142847699" style="zoom: 67%;" />

#### 基于深度学习的方法（图片分类）

![image-20231010174751323](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101747503.png)

#### 卷积神经网络CNN

![image-20231010174830772](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101748083.png)

CNN很像小朋友在搭积木，GoogLeNet考虑所有可能性

#### 区域卷积神经网络R-CNN

![image-20231010180502923](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101805827.png)

![image-20231010180618563](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101806804.png)

#### 配置

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310101806420.png" alt="image-20231010180646552" style="zoom:50%;" />

## [目标识别基础——alexnet模型（理论和代码复现）up主PULSE_](https://www.bilibili.com/video/BV1nU4y1x7nU?vd_source=30c6f8538ba84a9cd544b546db0da32b)(10.11-)

### 截图

![image-20231011095258842](C:/Users/14682/AppData/Roaming/Typora/typora-user-images/image-20231011095258842.png)

### 目标识别

![image-20231010222126055](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102221538.png)

任务由上至下

- 目标识别：小目标，先找一只猫！
- 目标检测**（识别加定位的工作）**：有多个目标，分清楚是猫猫，狗狗，还是鸭鸭！

![image-20231010222303251](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102223548.png)

我们看到这里彩色的定位框，左上角的标签就是它判定的种类，后面跟的就是它是这个种类的概率

- 目标分割：我们不光要把它框出来，而且要从像素级别上画出一个区域，这个区域里面都是狗，另外一个区域里面都是猫，没有被圈出来的就是背景。

![image-20231010222521903](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102225366.png)

这对于自动驾驶是很有价值，虽然自动驾驶的时候我们接收到的是视频，但这个也是一帧一帧的

- 目标跟踪：由于我截取一帧一帧是有位置关系的，所以我们可以做一个目标跟踪。

### 目标识别的起家——AlexNet（2012）

![image-20231010222816261](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102228050.png)

为什么是这个时候？因为在这之前GPU的算力刚被解放（2012年左右），现在可以用比较暴力的计算解决很多问题。

本次课程里还会提到之后的两条路线

- 双阶段 RCNN（**体现在识别和定位是两个任务**）
- 单阶段 YOLO（**将识别和定位放在一起做**）

### 目标：识别图片中的物体

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102231397.png" alt="image-20231010223121206" style="zoom:50%;" />

也就是说，你给电脑一张单目标的图片，电脑会给这个图片一个标签，说你这张图片里单个目标是个什么东西。

这个就是**AlexNet**要解决的任务。

### 先验知识：在讲解AlexNet结构之前

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102240058.png" alt="image-20231010224055849" style="zoom:67%;" />

![image-20231010224041706](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102240073.png)

![image-20231010224218264](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102242976.png)

#### RGB

我们看到手机上的画面是由无数个像素点构成，而每一个像素点则是由**三原色**构成（三个子像素，红绿蓝），而我们通过三原色比例的不同来呈现出成千上万种颜色，最终拼成画面。

**每个像素每种颜色可以负载2的8次方（256）种亮度级别。**

如果用三种颜色通道组合可以产生`256x256x256`种，就是一千六百多万种，而人眼能识别的颜色是百万级，所以绝对够用。

如果三种原色的亮度级别都为0就是黑色，亮度级别都为255就是白色。（255是最高亮度级别）

### 看回这张图（05：53）

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310102327537.png" alt="image-20231010232748676" style="zoom:50%;" />

比如输入一张长宽各227个像素的三通道（三张，三原色），三通道的一张图片，我们进行卷积操作。

在这里他先做了一个卷积操作，再做了一次池化，再做了一个卷积，再做了一次池化，再卷了三次卷积，再做了一次池化，最后得到一个全连接层，通过softmax运算得出一个结果。

听到这里我确实懵了，但是这里up主好温柔地解释了一下，这个运算大致每一步所做的运算。

像搭积木一样叠加的。

- 卷积层
- 池化层
- 全连接层

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310111021366.png" alt="image-20231011102136843" style="zoom:67%;" />

卷积——池化——规范化层——全连接层

卷积层和全连接层都是**学习层**，池化层和规范化层也不是。在每一个学习层之后都有一个**ReLU函数**

### 稍微讲了一下代码

```python
class AlexNet(nn.Module):
    def __init__(self, num_classes=2, init_weights=False):
        super(AlexNet, self).__init__()
        self.features = nn.Sequential(
            # 卷积
            nn.Conv2d(3, 48, kernel_size=11),  # input[3, 65,65]  output[48, 55, 55]
            # 这里是卷积层，做一个ReLU
            nn.ReLU(inplace=True),
            # 最大池化
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[48, 27, 27]
            # 规范化层（Norm层）
            nn.BatchNorm2d(48),
            # 卷积
            nn.Conv2d(48, 128, kernel_size=5, padding=2),           # output[128, 27, 27]
            # 卷积后ReLU
            nn.ReLU(inplace=True),
            # 最大池化
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 13, 13]
            # 规范化层
            nn.BatchNorm2d(128),
            # 卷积
            nn.Conv2d(128, 192, kernel_size=3, padding=1),          # output[192, 13, 13]
            # 卷积后ReLU
            nn.ReLU(inplace=True),
            # 卷积
            nn.Conv2d(192, 192, kernel_size=3, padding=1),          # output[192, 13, 13]
            # 卷积后ReLU
            nn.ReLU(inplace=True),
            # 卷积
            nn.Conv2d(192, 128, kernel_size=3, padding=1),          # output[128, 13, 13]
            # 卷积后ReLU
            nn.ReLU(inplace=True),
            # 最大池化
            nn.MaxPool2d(kernel_size=3, stride=2),                  # output[128, 6, 6],
        )
        self.classifier = nn.Sequential(
            nn.Dropout(p=0.5),
            # 这里的Linear都是全连接层，一共有三个，这是1
            nn.Linear(128 * 6 * 6, 2048),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5),
            # 2
            nn.Linear(2048, 2048),
            nn.ReLU(inplace=True),
            # 3
            nn.Linear(2048, num_classes),
        )
```

### 抽象概念讲解（卷积层、relu、池化层、norm层、全连接层）

![image-20231011103147105](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310111031578.png)

- 卷积层：提取特征
- ReLU函数：非线性表达能力
- 池化层：减少计算量
- norm层：规范数据分布
- 全连接层：分类

为了理解这些概念，我们还是需要理解一个大的概念，我们把那张图再拿回来。

![image-20231011104018851](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310111040570.png)

我们在这张图里所有的标签标识的都是**前向传播**的方向。

假定里面所做的运算都是定好的，然后把一张图片放进去之后只是机械的计算来得到一个最后的结果。

为什么给一张图它能给出结果，是由于**卷积层的卷积核**和**全连接层的权重**。这是真正起作用的。

在**全连接层的每一个点里面**，都相当于对它做了一个这样的加工`(x -> ax + b -> 输出)`，你输入给全连接层的是一个x，它会给x加一个系数a，加一个偏差b，然后再把这个结果做一个输出，传递给下一层。

#### LOSS函数（模型好坏的判断标准）

![image-20231011104601816](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310111046715.png)

##### 下山

最低点是模型判断高的时候。

如果权值训练得好，模型就做得好。

整个过程就是**先做前向传播得到一个loss值，根据loss值去做反向传播，再做反向传播的过程中，更新每一层的权值，更新权值之后，就相当于这个模型完成了一次学习**。我们向下山的地方迈了一步，不停迈步，就是不断学习。

学习：前向传播得到loss，反向传播更新权值，来来回回做很多遍，这就是下山的过程。

##### 梯度

就是上山最快的方向，如果我们给梯度取个负的，那么就是下山最快的方向。

梯度怎么算呢？就是**求偏导**。

#### 卷积层（对于输进来的图片进行一个运算）

怎么运算呢？

![image-20231011105305364](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310111053764.png)

在每一个卷积层的时候都会有一个**卷积核（就是那个小窗口）**，这个卷积核上面的数字可以决定你这一层学习的能力学得怎么样。

它的计算是比较简单的，把3x3的卷积核，比到左上角的一个3x3的像素，把他们对应位置进行**相乘**。

```
(-1 x 3) + (0 x 0) + (1 x 1)+
(-2 x 2) + (0 x 6) + (2 x 2)+
(-1 x 2) + (0 x 4) + (1 x 1)= -3
```

他们的结果（-3）就是用这个卷积核提取出来的这一小片的特征，在计算后的特征图上，他只会体现在这个（-3）上。因为这个（-3）参与计算的有它原图的一个小部分还有一个它的卷积核，所以你别看就（-3）一个数。

在这个特征图上的一个点，就是用卷积核在这个图上的这一小片区域提取出来的特征，至于我们这个特征提取得好与不好，**它是由这个工具来决定的（也就是这个卷积核上的数字）**。而我们在做反向传播的时候，更新的权值也就是这个卷积核上的数字。

也就是说，卷积核上的数字就是我们在做前向运算和反向运算过程中学到的东西，一种体现，另一种体现在全连接层，那里也有需要更新的权值。

#### 卷积的三种分类

[CNN基础知识——卷积（Convolution）、填充（Padding）、步长(Stride)](https://zhuanlan.zhihu.com/p/77471866)

![image-20231013194624387](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310131946240.png)

这里的valid和same，full都是padding

1. Valid卷积（变小）
2. Same卷积（不变）
3. Full卷积（变大）

- 输入卷积层的图片大小为（n*n）

- 滑窗（卷积核）的大小为（k*k）
- 填充padding大小为p

有时我们还希望输入和输出的大小应该保持一致。为解决这个问题，可以在进行卷积操作前，对原矩阵进行边界**填充（Padding）**，也就是在矩阵的边界上填充一些值，以增加矩阵的大小，通常都用“0”来进行填充的。

- 步长stride为s

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310132013680.png" alt="image-20231013201327855" style="zoom: 33%;" />

- 输出的特征图大小为（N*N）

三种卷积方式有共同的公式，就是`N = (n - k + 2p)/s + 1`

<img src="https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310131948020.png" alt="image-20231013194843869" style="zoom:50%;" />

#### 感受野

![image-20231013203110802](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310132031374.png)

这一张特征图对应原图就是它的感受野，对特征图再取特征。

![image-20231013203322182](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310132033222.png)

#### Relu函数

sigmoid函数激活层

![image-20231013203433593](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310132034927.png)

当我们要判断某一种数据是否存在某一种性质时，上面的x就是它的输入，当它更靠近左边，它就显得更没有这个特性，在右边就显得更有这个特性。在右边更接近于1.

做反向传播时要求导，给sigmoid求导就是它的斜率，而每一层都要做一个求导，所以我们希望这个范围在1，因为1x1x1还是1，而这个一会儿大一会儿小，梯度会爆炸，所以我们想了一个办法，做了Relu函数。

当没有达到某一个界限时，全部为0，求导时全部为1.它考虑了两点

- 一个是在前向传播的时候，要把它不达标的数据全部归0
- 达标的数据要求它的斜率，也就是反向传播的时候求斜率时是1

这样就满足激活层的要求。

非线性计算会提升模型的表达能力。





## Colab（10.12-）

### 简介

[Google Colab免费GPU 超详细使用教程](https://blog.csdn.net/weixin_39653948/article/details/105010730?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522167266963916800213032756%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=167266963916800213032756&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-105010730-null-null.142%5Ev68%5Econtrol,201%5Ev4%5Eadd_ask,213%5Ev2%5Et3_control2&utm_term=colab&spm=1018.2226.3001.4187)

[计算机视觉实战----AlexNet网络及使用colab跑YoloV5代码](https://blog.csdn.net/xiaoren886/article/details/128525921)

https://colab.research.google.com/notebooks/welcome.ipynb?pli=1#scrollTo=-gE-Ez1qtyIA

![image-20231012213432798](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122134894.png)

![image-20231012213630597](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122136932.png)

```
ctrl + enter 执行，或者点击左边那个播放键
```

### 机器学习

![image-20231012214032843](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122140611.png)

```python
from google.colab import drive
drive.mount('/content/drive')
```

![image-20231012214420265](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122144485.png)

```
# test-colab
https://colab.research.google.com/drive/12oJot5ug1ivwbDUntjUd29oWnau_Fctn#scrollTo=qeGeKa5uIpNj 
# google-cloud
https://drive.google.com/drive	
```

![image-20231012215024234](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122150228.png)

### 云端硬盘

![image-20231012215434498](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122154219.png)

### 使用GPU

![image-20231012215833242](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122158035.png)

![image-20231012215928832](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122159212.png)

![image-20231012220103371](https://cdn.jsdelivr.net/gh/rainsbluechan/blogimage@main/img/202310122201535.png)

